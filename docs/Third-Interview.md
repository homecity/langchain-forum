# LS Prompt

### **Background**

We want to see how you think like a builder and support engineer ‚Äî how you learn tools, experiment with features, and communicate technical feedback. This task is designed to assess your ability to understand and work with **LangSmith and LangGraph**.

**LangGraph** is a library for building stateful, multi-step applications powered by LLMs. It enables the creation of agents and workflows that can manage memory, looping, conditional branching, and other logic needed for more sophisticated applications.

**LangSmith** experiments allow users to test and evaluate those applications ‚Äî including LangGraph-powered agents ‚Äî using datasets and scoring functions like LLM-as-a-judge.

We‚Äôre not looking for perfection or polish ‚Äî we‚Äôre looking for signal in your thinking:

- How do you reason about LangGraph‚Äôs design model (nodes, edges, states)?
- How do you connect LangGraph applications with LangSmith evaluation tools?
- Can you identify what‚Äôs working, what‚Äôs confusing, and how it could improve?

-----

### **What You‚Äôll Be Doing**

Your task is to build a simple **agent** of your choice using **LangGraph** and then **run an evaluation experiment in LangSmith**, using both the **SDK** and the **UI**.

LangGraph provides low-level infrastructure for long-running, stateful workflows and agents. LangSmith lets you evaluate these workflows using test datasets, custom metrics, and LLM-based scoring to measure attributes like correctness, helpfulness, or hallucination.

This simulates a realistic developer scenario: testing and refining a LangGraph application with LangSmith‚Äôs tools.

### **Task**

1. Design and build a simple LangGraph-based agent or workflow (e.g., retrieval-augmented agent, multi-step QA, or tool-using planner).
1. Create or select a small dataset (can be synthetic) to test your app.
1. Run a LangSmith evaluation experiment using both:
- The **LangSmith UI**, and
- The **LangSmith SDK** (programmatically)
1. Focus on realism ‚Äî debug or improve your agent like a real user would.

### Resources

- üîß [LangGraph Docs](https://docs.langchain.com/langgraph/)
- üìò [LangSmith Evaluation Docs](https://docs.smith.langchain.com/evaluation)
- üéì [LangSmith Academy](https://academy.langchain.com/courses/intro-to-langsmith)

### **What to Share**

- A **short walkthrough (~15 min)** on our next call covering:
  - What you built using LangGraph
  - How you evaluated it with LangSmith
  - What you learned or found surprising
  - What might confuse a new user
- A link to your **code snippets or repo**
- Optionally, a **‚Äúfriction log‚Äù** ‚Äî anything unclear, buggy, or unintuitive you‚Äôd flag to the team if you were already on the job